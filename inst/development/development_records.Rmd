---
title: "Development records notebook"
author: "Pedro Ivo Guimarães"
description: LambdaPCR development archiving notebook
output: html_notebook
---

# February 

## Packages and global options

```{r packages, message=FALSE, warning=FALSE}
library(tidyverse)
library(stringr)
library(ggforce)
library(cowplot)
library(RcppRoll)
source("~/proposal_prelimn/code/libraries_and_global_opts.R")
```

## 02-26-18

### Importing sequences

The most basic function of this app is importing a sequence file on FASTA format. The imported file can either be the *template* sequence or the *target* sequence. The target sequence is the DNA sequence of the gene of interest that will be inserted into the template sequence. We can create a basic function to import a DNA sequence with two derived functions, one for each type of input:

```{r read-sequence-fun}
read_sequence <- function(file, ...) {
  raw <- as_data_frame(read_file(file))
  
  df <-raw %>%
    separate_rows(value, sep = '\n>') %>%
    separate(value, into = c('header', 'seq'), sep = '\n', extra = 'merge') %>%
    mutate(
      seq = str_replace_all(seq, '\n', ''),
      header = str_replace(header, '>', ''),
      length = nchar(seq)
    )
}

template <- read_sequence("../data/puc19.fasta")
target <- read_sequence("../data/GFP sequence.fasta")
```

## 02-28-18

### Updating `read_sequence` function

An useful functionality of `read_sequence` would be simplifying the sequence header information by allowing the user provide a `header_structure` vector — containing the naming scheme of the sequence header — and `id_field` — the field that will be used as the seq id:

```{r fun-read-sequence-update}
read_sequence <- function(file, id_field = NULL, separator = NULL) {
  raw <- as_data_frame(read_file(file))
  
  df <- raw %>%
    separate_rows(value, sep = '\n>') %>%
    separate(value, into = c('header', 'seq'), sep = '\n', extra = 'merge') %>%
    mutate(
      seq = str_replace_all(seq, '\n', ''),
      header = str_replace(header, '>', ''),
      length = nchar(seq)
    )
  
  #Checking if optional parameters were passed
  if(is.null(id_field)) {
    id_field <- 'id'
  }
  if(is.null(separator)) {
    separator <- '\\|'
  }
  
  #Creating sequence id from seq header
  df <- df %>%
    separate(header, into = id_field, extra = 'drop', sep = separator)
}

template <- read_sequence("../data/puc19.fasta")
target <- read_sequence("../data/GFP sequence.fasta")
```

# March

## 03-01-18

### Update `read_sequence` to add `type` tag to sequences

The `read_sequence` function does not differentiate if the sequence object is a template or a target gene object, so I'll update it again to import the DNA sequences and add a tag `template` or `target`:

```{r fun-read-sequence-update-2}
read_sequence <- function(file, input_type, id_field = NULL, separator = NULL) {
  raw <- as_data_frame(read_file(file))
  
  df <- raw %>%
    separate_rows(value, sep = '\n>') %>%
    separate(value, into = c('header', 'seq'), sep = '\n', extra = 'merge') %>%
    mutate(
      type = input_type,
      seq = str_replace_all(seq, '\n', ''),
      header = str_replace(header, '>', ''),
      length = nchar(seq)
    )
  
  #Checking if optional parameters were passed
  if(is.null(id_field)) {
    id_field <- 'id'
  }
  if(is.null(separator)) {
    separator <- '\\|'
  }
  
  #Creating sequence id from seq header
  df <- df %>%
    separate(header, into = id_field, remove = F, extra = 'drop', sep = separator)
}

template <- read_sequence("../data/puc19.fasta", input_type = 'template')
target <- read_sequence("../data/GFP sequence.fasta", input_type = 'target')
```

### Design primers for gene insertion

#### Extract template and target gene sequence overlaps for primer design
The simplest design case for Lambda PCR is the insertion of the target gene in a defined location in the destination plasmid. The first thing we need to do is write a function that will collect the extract the *n*-length flanking regions to the left and right of the insertion site and store as the template-overlaping tails of the primers. 

As a starting condition, let's extract $n = 15$ bps around the insertion site:

```{r template-overlap-extraction}
# insertion_coordinate <- 1500
# ins_flank_length <- 20
# target_primer_length <- 15

#Functions to extract flanking sequences from insertion site:
get_overlaps <- function(seq_object, position=NULL, length=NULL) {
  #Initialize empty overlap object
  overlaps <- tibble(
    id = character(),
    type = character(),
    origin = character(),
    seq = character()
  )
  
  #Checking what type of object was passed to function:
  if(seq_object$type == 'template') {
    #Using default overlap length of 20 if not provided:
    overlap_length <- ifelse(is.null(length), 20, length)
    #Extracting overlaps
    overlap_left <- substr(seq_object$seq, (position-overlap_length), position)
    overlap_right <- substr(seq_object$seq, (position+1), (overlap_length+position+1))
    #Populating overlap object:
    overlaps <- overlaps %>% 
      add_row(id = 'left', type = 'overlap', origin = 'template', seq = overlap_left) %>%
      add_row(id = 'right', type = 'overlap', origin = 'template', seq = overlap_right)
  } else {
    #Using default overlap length of 20 if not provided:
    overlap_length <- ifelse(is.null(length), 15, length)
    #Extracting overlaps
    overlap_left <- substr(seq_object$seq, 1, overlap_length)
    overlap_right <- substr(seq_object$seq, seq_object$length-overlap_length, seq_object$length)
    #Populating overlap object:
    overlaps <- overlaps %>% 
      add_row(id = 'left', type = 'overlap', origin = 'target', seq = overlap_left) %>%
      add_row(id = 'right', type = 'overlap', origin = 'target', seq = overlap_right)
  }
}

overlaps_template <- get_overlaps(template, position = 1500)
overlaps_target <- get_overlaps(target)
```

#### Complement and reverse complement functions: 

```{r fun-seq-convertion}
complement <- function(sequence) {
  seq <- toupper(sequence)
  complement <- chartr('ATCG', 'TAGC', seq)
}

reverse_complement <- function(sequence) {
  complement <- complement(sequence)
  revcomp <- stringi::stri_reverse(complement)
}

```

#### Correct primer orientations

Primer design for LambdaPCR is tricky because there are special rules that need to be followed regarding the primer tails. I had to use colored markers to understand what to do:

```{r primer-design-guide-img}
knitr::include_graphics("~/Downloads/Lambapcr_primer_rules.jpg")
knitr::include_graphics("~/Desktop/lambdapcr_overview.png")
```

So, in order to design the primers for the first PCR of LambdaPCR, we have to use the following rules:

- Forward primer: template left overlap + target left overlap, 5'-3' orientation
- Reverser primer: complement of target right overlap + complement of template right overlap,  5'-3' orientation

Now that we have the overlaps for both the template and the target sequences, we can create our first LambdaPCR primer pair:

```{r fun-create-primers}
create_primers <- function(overlaps_target, overlaps_template) {
  overlaps <- bind_rows(overlaps_target, overlaps_template)
  
  primers <- overlaps %>%
    spread(origin, seq) %>%
    select(-type) %>%
    mutate(
      seq = case_when(
        id == 'left' ~ paste(tolower(template), 
                             target, 
                             sep = ''),
        id == 'right' ~ paste(tolower(reverse_complement(template)), 
                              reverse_complement(target), 
                              sep = ''
                              )
      )
    ) %>%
    mutate(id = case_when(
      id == 'left' ~ gsub('left', 'forward', id),
      id == 'right' ~ gsub('right', 'reverse', id)
    )) %>%
    mutate(type = 'primer') %>%
    select(-target, -template)
}

primers <- create_primers(overlaps_target, overlaps_template)
```

## 03/08/18

### `lambdaPrimer` flowchart

```{r diagrammer-test}
library(DiagrammeR)

grViz("
  digraph lambdaPrimeR_dataflow {
    rankdir='LR';
    # splines='ortho';
    #internal object nodes:
    node [shape = circle]
    input; overlaps; primers; score
    
    #Input and output nodes 
    node [shape = box]
    target; template; ins_position; report

    #Function nodes:
    node [shape = plaintext]
    read_sequences; get_overlaps; create_primer; melt_temp;
    hairpin_prob; primer_score; rank_primers; mutate_primer;
    report_best_primers
    
    #Edges:
    target -> read_sequences; template -> read_sequences; 
    read_sequences -> input; input -> get_overlaps;
    ins_position -> get_overlaps; get_overlaps -> overlaps; 
    overlaps -> create_primer; create_primer -> primers;
    primers -> report_best_primers; report_best_primers -> report
    
    subgraph cluster_ga {
      primers -> melt_temp; primers -> hairpin_prob;
      hairpin_prob -> primer_score; melt_temp -> primer_score;
      primer_score -> score; score -> rank_primers; 
      rank_primers -> mutate_primer; mutate_primer -> primers;
      label = 'Genetic algorithm'
    }
    
  }
")

```

## 03/09/2018

### Melting temperature calculation with MELTING tool

Today I am learning how to use the [MELTING](https://www.ebi.ac.uk/biomodels/tools/melting/) tool to calculate the melting temperature of primers. Accoring to the documenation, the following options are mandatory:

```
Mandatory options :

-S [sequence]
	Nucleic acid sequence, mandatory. The sens of this sequence must be 5'-3'.


-C [complementary sequence]
	Nucleic acid complementary sequence, mandatory only if there is inosine bases 
	or azobenznes in the sequence entered with the opton -S. The sens of this 
	sequence must be 3'-5''.

-E [agent1=concentration1:agent2=concentration2]
	Different agent concentrations in the solution. The agents can be cations 
	(Na, K, Tris, Mg for Na+, K+, Tris+ and Mg2+), dNTP or other agents 
	(DMSO, formamide). The concentrations must be in Mol/L but there are some 
	exceptions : DMSO is a percentage, formamide is a percentage if the method 
	lincorr is chosen and in Mol/L if the method bla96 is chosen. At least one 
	cation concentration is mandatory, the other agents are optional. See the 
	documentation for the concentration limits. It depends on the used correction.

-P [nucleotide concentration]
	Concentration in mol/L of the nucleic acid strand in excess, mandatory.

-H [hybridization]
	Type of hybridization, mandatory. Four types of hybridization are allowed: 
	dnadna (DNA duplex), rnarna (RNA duplex), dnarna or rnadna (hybrid DNA/RNA) 
	and mrnarna or rnamrna (2-o-methyl RNA/ RNA). The type of hybridization 
	defines the kind of the sequence and its complementary. 
		Ex : dnarna = the sequence (entered with the option -S) is a DNA sequence 
		and its complementary (entered with the option -C) is a RNA sequence.
		Ex : rnadna = the sequence (entered with the option -S) is a RNA sequence 
		and its complementary (entered with the option -C) is a DNA sequence  
```

We can use the following command to calculate the melting temperature of a
DNA-DNA hybridization:

```{bash}
/Users/pedro_work/MELTING5.1.1/executable/melting -S ATGGTGAGCAAGGGC -H dnadna 
-P 1e-7 -E Mg=1
```


### Integrating MELTING and R

To test the MELTING tool, I am going to use the `lambdaPrimeR` test primer 
sequences. The test primers are designed using the GFP gene sequence as target
and the pUC19 plasmid sequence as template. The insertion coordinate is 1500. 

```{r create-test-primers}
#Input sequences:
target <- system.file('extdata', 'GFP sequence.fasta', package = 'lambdaPrimeR')
template <- system.file('extdata', 'puc19.fasta', package = 'lambdaPrimeR')
inputs <- read_sequences(target, input_type = 'target')
inputs <- read_sequences(template, input_df = inputs, input_type = 'template')

#get sequence overlaps:
overlaps <- get_overlaps(inputs, 1500)
primers <- create_primer_pair(overlaps)
```

```{r pimers-object}
primers
```

Let's use the forward primer to test if we can use R to call MELTING to calculate
the melting temperature fr the annealing reagions of the primer, and return the
value back to R. The idea for this function came from [here](https://darrenjw.wordpress.com/2011/01/01/calling-java-code-from-r/).

```{r fun-melt-temperature}
primer <- toupper(primers$seq[primers$id == 'forward'])
melt_temperature <- function(sequence, template_conc, ion_conc) {
  melting_path <- "/Users/pedro_work/MELTING5.1.1/executable/melting"
  melting_command <- paste(melting_path, '-S', sequence, '-H dnadna', '-P',
                           template_conc, '-E', ion_conc)
  system(melting_command, intern = T)
}

melt_temp_test <- melt_temperature(primer, 1e-07, 'Mg=1')
```

```{r melt-temp-output}
melt_temp_test
```

## 03/10/18

### Updating `melt_temperature` function to parse `melting` command output

```{r fun-melt-temperature-update}
melt_temperature <- function(sequence, template_conc, ion_conc) {
  melting_path <- "/Users/pedro_work/MELTING5.1.1/executable/melting"
  melting_command <- paste(melting_path, '-S', sequence, '-H dnadna', '-P',
                           template_conc, '-E', ion_conc)
  out <- system(melting_command, intern = T)
  
  #Creting melting temperature dataframe:
  melt_temp <- tibble(raw = out[5]) %>%
    mutate(
      primer = sequence,
      tm = as.numeric(str_extract(raw, '\\d+\\.\\d+'))
    ) %>%
    select(-raw)
}

melt_temp <- melt_temperature(primer, template_conc = 1e-7, ion_conc = 'Mg=1')
```

```{r melt-temp-output-update}
melt_temp
```

## 03/14/18

### Using NUPACK to calculate hairpin formation probability

Today I am learning how to use NUPACK to calculate the probability of hairpin
formation on the template-overlaping regions of the $\lambda$-PCR primers. The
reason for this is that the formation of hairpins in the annealing regions of
the mega-primer could cause the DNA polymerase to dettach from the DNA template,
and NUPACk is capable of calculating the probability of a base being bound and
unbound to any other base in the sequence.

In order to test NUPACK, I'll use the sequence of the GFP gene with the 
template-overlap flanking regions as the test input.

```{r nupack_test_input, warning=FALSE, message=FALSE}
test_file <- system.file("extdata", "nupack_test_seq.in",
                          package = "lambdaPrimeR")

test_seq <- read_file(test_file)

test_seq
nchar(test_seq)
```

The command to run NUPACK to calculate the pair formation probability of the
input sequence is:

```{bash nupack-command, eval=FALSE}
cd /Users/pedro_work/lambdaPrimeR/inst/extdata
time pairs -T 45 -material dna nupack_test_seq
```
```
real	2m2.072s
user	2m0.107s
sys	0m1.582s
```
This command produced an output called `nupack_test_seq.ppairs`, that contains
the calculation of the base pair formation probabilities:

```{r nupack-output}
nupack_output <- read_lines("../extdata/nupack_test_seq.ppairs")
head(nupack_output, 25)
```

According to the NUPACK manual, the `nupack_test_seq.ppairs` contains the 
probability of formation of each base pair in the secondary structure of the 
input sequence: 

```{r pairs-command-man-page, echo=FALSE}
knitr::include_graphics(path = "./nupack_pairs_command_manual_page.pdf")
```

We can extract the probabilities that a base will be unpaired from
`nupack_test_seq.ppairs` and store it in a dataframe:

```{r base-pair-probabilities}
unpaired_probabilities <- tibble(lines = nupack_output) %>%
  filter(grepl('^\\d+\\t', lines)) %>%
  separate(lines, into = c('ibase', 'jbase', 'p'), sep = '\t') %>%
  mutate_all(as.numeric) %>%
  filter(jbase == nchar(test_seq)+1)
  
unpaired_probabilities
```

The `p` column contains the probabilities of a base to be unbound at the
the specified melting temperature (T~m~ = 45 ºC). We can use this column to plot
the variation in probability throughout the target gene sequence:

```{r prob-plot-target-gene}
#Full sequenc
zoom_left <- ggplot(unpaired_probabilities, 
                    aes(x=ibase, y=p, color = ibase >= 40))+
  geom_line(size = 0.5)+
  geom_point(size = 1) + 
  xlab('Base i')+
  ylab('Prob. that base i is unpaired')+
  theme_bw()+
  facet_zoom(x = ibase <= 40, zoom.size = 1.5)+
  scale_color_manual(values = greenfocus)+

  theme(legend.position = "none")

zoom_right <- ggplot(unpaired_probabilities, 
                    aes(x=ibase, y=p, color = ibase <= nchar(test_seq) - 40))+
  geom_line(size = 0.5)+
  geom_point(size = 1) + 
  xlab('Base i')+
  ylab('Prob. that base i is unpaired')+
  facet_zoom(x = ibase >= nchar(test_seq)-40, zoom.size = 1.5)+
  theme_bw()+
  scale_color_manual(values = greenfocus)+
  theme(legend.position = "none")

plot <- plot_grid(zoom_left, zoom_right, ncol = 2,  labels = 'auto')
plot
```

We can see that the unpairing probability varies a lot from base to base
throughout the sequence. We can calculate local probilities of a k-mer of length
$l$ to have a better idea of how the probability changes with position:

```{r unpaired-prob-kmer}
window_size <- c(2, 4, 20, 50, 100, nchar(test_seq))

kmer_probabilities <- tibble(l = window_size) %>%
  group_by(l) %>%
  do(
    cummprod = roll_prodl(unpaired_probabilities$p, n = .)
  ) %>%
  unnest() 
```

## 03/15/18

### Testing NUPACK with mega-primer fragments

Let's check how the base-pairing probabilities calculated by NUPACK will change 
if we use only the edges of the mega-primer sequence. The default overlap 
lengths in the `lambdaPrimeR`-generated primes are 20bp template overlaps and 
15 bp target gene overlap. So, for this first test, we'll use only the firts 
40bp of each end of mega-primer sequence:

```{r megaprimer-seq-edges-extract}
#extracting edges:
fiveprime_end_seq <- substr(test_seq, 1, 40)
threeprime_end_seq <- substr(test_seq, (nchar(test_seq)-40), nchar(test_seq))

#Writing NUPACK input files
write_file(fiveprime_end_seq, 'notebook_data/gfp_puc19_frag_5p.in')
write_file(threeprime_end_seq, 'notebook_data/gfp_puc19_frag_3p.in')
```

We can write a function that will pass the input files to NUPACK and retrieve
the output:
```{r run-nupack-function}
run_nupack <- function(input_file, melting_temperature, paired=TRUE) {
  #Extracting file prefix:
  file_prefix <- gsub('.in$', '', input_file)
  output_file_name <- gsub('.in$', '.ppairs', input_file)
  
  #Input sequence length:
  input_seq <- read_file(input_file)
  
  #Running NUPACK with the input file
  nupack_command <- paste('time', 'pairs', '-T', melting_temperature,
                          '-material dna', file_prefix)
  system(nupack_command, intern = T)
  
  #Import output file and extract base pair probabilities:
  nupack_output <- read_lines(output_file_name)
  # print(head(nupack_output, 20))
  
  unpaired_probabilities <- tibble(lines = nupack_output) %>%
    filter(grepl('^\\d+\\t', lines)) %>%
    separate(lines, into = c('ibase', 'jbase', 'p'), sep = '\t') %>%
    mutate_all(as.numeric) 
  
  if(paired) {
    unpaired_probabilities %>%
      filter(jbase < nchar(input_seq)+1)
  } else {
    unpaired_probabilities %>%
      filter(jbase == nchar(input_seq)+1)
  }
    
}
```

```{r run-nupack-seq-fragments-test}
seq_fragments <- dir(path = '~/lambdaPrimeR/inst/development/notebook_data/', 
                     pattern = '*.in', full.names = T)

nupack_outputs <- tibble(input = seq_fragments) %>%
  group_by(input) %>%
  do(
    nupack_output = run_nupack(.$input, 45, paired = F)
  ) %>%
  unnest() %>%
  mutate(input = basename(input))
```

NUPACK runs much faster on smaller sequences (duh). We need to check if the base
pair formation probability changed now that we used only the edges of the mega
primer:

```{r base-pair-prob-edges}
unpaired_probabilities <- unpaired_probabilities %>%
  mutate(input = case_when(
    ibase <= 40 ~ 'gfp_puc19_full_5p',
    ibase >= (nchar(test_seq) - 40) ~ 'gfp_puc19_full_3p',
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(input)) %>%
  group_by(input) %>%
  mutate(ibase = row_number())


edge_vs_full_seq_prob <- bind_rows(nupack_outputs, unpaired_probabilities) %>%
  mutate(input = gsub('.in', '', input)) %>%
  separate(input, into = c('target', 'template', 'input_type', 'end'), sep = '_')

plot <- ggplot(edge_vs_full_seq_prob, aes(x = ibase, y = p, color = input_type))
plot+
  facet_grid( ~ end, scales = 'free_x')+
  geom_line()+
  geom_point()+
  xlab('Base i')+
  ylab('Prob. of base i being unpaired')+
  scale_color_manual(values = plot_pallets$tol2qualitative, name = "Input type",
                     labels = c('Sequence edges', 'Full sequence'))
  
```

It looks like **there are very changes on the base pair probabilities calculated 
by NUPACK when just the edges of the mega primer are used as input**. This is a 
very good result as it means that I don't need to use the mega primer entire 
sequence for this step, reducing the running time significantly. 

## 03/16/18

### Continuing testing NUPACK with mega-primer fragments

My hypothesis is that using just the mega primer edges improves the probability
of a base to be unpaired because NUPACK cannot calculate the probability of two 
distant bases pairing. We can check if this is the case by ploting the base pair
coordinates and see if the NUPACK runs with just the edges does not contain
pairs formed by two distant bases.

```{r base-pair-coordinates-data, warning=FALSE, message=FALSE}
full_seq_paired_bases <- tibble(lines = nupack_output) %>%
  filter(grepl('^\\d+\\t', lines)) %>%
  separate(lines, into = c('ibase', 'jbase', 'p'), sep = '\t') %>%
  mutate_all(as.numeric) %>%
  filter(jbase < nchar(test_seq)+1) %>%
  mutate(input = case_when(
    ibase <= 40 ~ 'gfp_puc19_full_5p',
    ibase >= (nchar(test_seq) - 40) ~ 'gfp_puc19_full_3p',
    TRUE ~ NA_character_
  )) %>%
  filter(!is.na(input))
  

fragments_paired_prob <- tibble(input = seq_fragments) %>%
  group_by(input) %>%
  do(
    nupack_output = run_nupack(.$input, 45, paired = T)
  ) %>%
  unnest() %>%
  mutate(
    input = basename(input),
    ibase = ifelse(input == 'gfp_puc19_frag_3p.in', 
                   ibase + nchar(test_seq) - 41,
                   ibase),
    jbase = ifelse(input == 'gfp_puc19_frag_3p.in', 
                   jbase + nchar(test_seq) - 41,
                   jbase)
  )

edge_vs_full_base_pair_prob <- 
  bind_rows(fragments_paired_prob, full_seq_paired_bases) %>%
  mutate(input = gsub('.in', '', input)) %>%
  separate(input, into = c('target', 'template', 'input_type', 'end'), sep = '_')
```

```{r base-pair-energy-plot, echo=FALSE}
prob_plots <- edge_vs_full_base_pair_prob %>%
  group_by(input_type) %>%
  do(
    plots = 
      ggplot(., aes(x=ibase, y=jbase, color = p)) +
      facet_wrap(~ input_type, scales = 'free') +
      geom_point()+
      facet_zoom(x=ibase<100)+
      scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "Spectral")))
  )
  
plot_grid(plotlist = prob_plots$plots, ncol = 2, labels = 'auto')
```

```{r base-pair-prob-plot, echo=FALSE}
prob_plots <- edge_vs_full_base_pair_prob %>%
  group_by(end) %>%
  do(
    plots = 
      ggplot(., aes(x=ibase, y=jbase, color = p, z=p))+
      facet_grid( ~ input_type, scales = 'free')+
      geom_point()+
      # stat_summary_hex(bins = 50)+
      scale_color_gradientn(colors = rev(RColorBrewer::brewer.pal(11, "Spectral")))
  )
  
plot_grid(plotlist = prob_plots$plots, nrow = 2, labels = 'auto')

  

```

We can see that most of the changes in the base pairing probability occurs at 
the 5' end of the mega-primer sequence. By using only the first 40 bp of the
left end, we don't take into consideration the probability of these bases to 
bind to distant bases (200-400 bp distant), increasing our unpaired probability.

### Function to break the mega-primer sequence into smaller fragments

```{r seq-fragmentor}
split_sequence <- function(input_sequence, fragment_length) {
  string <- toupper(input_sequence)
  pattern <- paste('(?<=.{', fragment_length, '})', sep = '')
  fragments <- strsplit(input_sequence, pattern, perl=T)
} 

test <- split_sequence(test_seq, 5)
test
```

